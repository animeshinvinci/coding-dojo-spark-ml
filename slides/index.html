<!DOCTYPE html>
<html>
  <head>
    <title>Hands-On Machine Learning</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      p {
        margin-top: 2em;
      }
      li {
        margin-top: 1em;
      }

      .section {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .section h1, .section h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      .lab {
        background: #525495;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .lab h1, .lab h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle, section

# Spark

---

class: center, middle, section

# RDDs

# Resilient Distributed Datasets

---

class: center, middle, lab

# Lab 1.1 - Compute

---

class: center, middle, section

# DataFrames

---

class: center, middle, section

# Machine Learning

---

# Machine Learning

Learn from existing data → model

Apply the model on new data

Categories:

- Supervised learning
- Unsupervised learning
- Recommendation

---

# Supervised learning

Training data = Features + Label

Predict the label on new data

**Classification:** label = class

- E.g. classifiy mails: spam / non-spam

**Regression:** label = continuous variable

- E.g. price for a second hand car

---

# Unsupervised learning

Training data = Features

Build clusters of points based on similarities

**Clustering:** classify into clusters

- E.g. find groups of similar people

---

# Workflow

1. Data Cleansing
1. Feature Engineering
1. Train a Machine Learning model
  1. Split the dataset: training/validation/test datasets
  1. Train the model
1. Apply the model on new data

---

# Data Cleansing

- Convert strings to numbers / booleans / ...
- Parse dates
- Handle missing values
- Handle data in an incorrect format
- ...

---

# Feature Engineering

- Transform data into numerical features
- E.g.:
  - A birth date → age
  - Dates of phone calls → Number of calls
  - Text → Vector of words
  - 2 names → Levenshtein distance

<img src="img/features_engineering.png" width="700">

---

# Machine Learning

<img src="img/ml_model.png" width="250" style="float:right">

- Train a model
- Test an algorithm with different params
  - Cross validation (Grid Search)
- Compare different algorithms, e.g.:
  - Logistic regression
  - Gradient boosting trees
  - Random forest

---

# Machine Learning

- Evaluate the performance of the model
  - E.g.: ROC curve
- Examine predictions
  - False positives, false negatives...

<img src="img/roc_curve.png" width="250"> <img src="img/predictions.png" width="250">

---

# Spark ML / MLlib's API

- **Spark MLlib**: low-level API
  - Data types: `Vector`, `LabeledPoint`...
  - Algorithms: `LinearRegressionWithSGD`, `DecisionTree`...
- **Spark ML**: higher-level (pipeline...)
  - Transformer: `DataFrame` → `DataFrame`
  - Estimator: `DataFrame` → `Model`

---

# How to use the API

1. Load data into a DataFrame
1. Do some feature engineering
  - Specific conversions
  - Index categorical features: `StringIndexer`
  - Assemble vectors: `VectorAssembler`
1. Split the data set into training &amp; test data sets
  - `df.randomSplit(Array(0.80, 0.20))`
1. Instantiate the algorithm &amp; define params
1. Call the `fit()` method to get a model
1. Call the `transform()` method to make predictions

---

class: center, middle, lab

# Lab 1.1 - Linear Regression

---

# Linear Regression

- Model the relationship between a **continuous** variable and explanoratory variables

<img src="img/linear_regression_equation.png" width="300">

<img src="img/linear_regression.png" width="400">

---

# Use case

Predict the age from other characteristics

<img src="img/data_bank.png" width="100%">

---

# Lab - `RegressionMain`

Feature Engineering

- fill NAs
- standardize each feature
- assemble a vector of features

Split the data set:

- training data set: 80%
- test data set: 20%

Train the algorithm

- Spark MLlib: `LinearRegression`
- Test the model

---

class: center, middle, lab

# Lab 1.2 - Gradient Boosted Tree Regression

## (Optional)

---

# Gradient Boosted Tree Regression

- Ensemble of weak prediction models
- Optimization of a differentiable loss function

Compare with Linear Regression:

- Spark MLlib: `GBTRegressor`
- Test different values for the `maxDepth` and `stepSize` parameters

---

class: center, middle, lab

# Lab 1.3 - Grid Search &amp; Cross Validation

## (Optional)

---

# Grid Search

- Test each combination of parameters (grid)
- Return the best-performing model using an evaluator

- Spark MLlib: `ParamGridBuilder`

---

# Evaluation of the error

- Root Mean Square error

<img src="img/rmse.png" width="60%">

- Spark MLlib: `RegressionEvaluator`

---

# Cross Validation

- k-fold validation

<img src="img/cross_validation.png" width="80%">

- Spark MLlib: `CrossValidator`

---

class: center, middle, lab

# Lab 2.1 - Classification

## Logistic Regression

---

# Logistic Regression

- Model the relationship between a **binary** variable and explanoratory variables

---

# Use case

Predict whether the person will purchase a subscription ("y") from other characteristics

<img src="img/data_bank.png" width="100%">

---

# Spark ML Pipelines

- Pipeline = Transformers + Estimator
- Call `pipeline.fit()` to train a model

<img src="img/pipeline_fit.png" width="65%">

- Call `model.transform()` to apply the model

<img src="img/pipeline_transform.png" width="65%">

---

# Lab - `ClassificationMain`

Feature Engineering

- index the "y" column into a "label" column
- index other features
- assemble a vector of features

Split the data set:

- training data set: 80%
- test data set: 20%

Train the algorithm

- Spark MLlib: `LogisticRegression`
- Test the model

---

class: center, middle, lab

# Lab 2.2 - Grid Search &amp; Cross Validation

## (Optional)

---

# Grid Search

*See Lab 1.3*

---

# Evaluation of the error

- Binary evaluator

- Spark MLlib: `BinaryClassificationEvaluator`

---

# Cross Validation

*See Lab 1.3*

- Spark MLlib: `CrossValidator`

---

class: center, middle, lab

# Lab 2.3 - Random Forests

---

# Random Forests

- Decision tree: fixed set of decisions to make a choice
- Random forests:
  - Many decision trees
  - Each tree uses a random selection of features
  - Final decision = average of all the decisions

- Spark MLlib: `RandomForestClassifier`

    </textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>
